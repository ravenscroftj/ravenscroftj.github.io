
- ## Statement on [[Jul 18th, 2022]]
	- Government intend to regulate AI in a context-driven way to avoid stifling innovation
	- The values are:
		- Context specific
		- Pro-innovation and risk-based - regulators should focus on high risk systems that pose real threats and not impose controls on systems that pose low or hypothetical risk
		- Coherent
		- Proportionate and adaptable -regulators should consider light touch options in the first instance
	- They define AI systems as Adaptive and Autonomous - they give example of language transformer and self-driving control system
	- Existing regulatory bodies will be required to implement their own regulations based on their interpretations of the guidelines
	- They also list a set of cross-sectoral principles to provide a coherent response:
		- They propose an early set of principles based on the [OECD Principles on Artificial Intelligence](https://oecd.ai/en/ai-principles)
			- AI must be used safely - regulators must consider what risks an AI system could pose in their given sector/domain - this should be commensurate with actual risk comparable with non-AI use cases
			- Systems must be technically secure and function as designed - make sure that the public have confidence in the proper functioning of systems - this requires systems to have been tested and proven
			- AI must be appropiately transparent and explainable
				- the government acknowledge that achieving exlainability of AI systems remains a research and development challenge and that current systems can't always be interpreted in an intelligible way.
				- In some circumstances, regulators may prohibit decisions that cannot be explained entirely.
				- Transparency requirements could involve proactive or retrospective provision of information relating to: **_nb: this sounds like model cards_**
					- the nature and purpose of the AI in question including information relating to specific outcomes
					- The data being used and information relating to training data
					- Logic and process used, where relevant information to support explainability of decision making
					- accountability for the AI and specific outcomes
			- Embed considerations of fairness into AI
				- In contexts where outcomes can impact people's lives - e.g. credit scoring, job applications, data points used to make decisions must be justifiable and not arbitrary
				- In practice this would probably need to involve being fairly selective about which features are used to train a model and perhaps keeping a justification on file for each column.
				- Regulator are to be allowed to define fairness and enforce appropriate governance for 'fairness' as appropriate for the sectors and entities that they regulate
			- Define a legal persons' responsibility for AI governance
				- Outcomes from an AI system are to be accountable to an individual or corporation.
			- Clarify routes to redress or contestability
				- Subject to proportionality, AI should not remove an affected individual or group's ability to contest an outcome. Regulators should require entities to ensure that outcomes can be contested in relevant situations.
-